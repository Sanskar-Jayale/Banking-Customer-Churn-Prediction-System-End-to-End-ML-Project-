import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


df = pd.read_csv(r"D:\Pro\End-to-end-churn-model\data\Bank-Customer-Attrition-Insights-Data.csv")
df.head()


df.info()


df.describe()


df.columns = df.columns.str.strip().str.lower().str.replace(' ','_')


card_type_dis = df['card_type'].value_counts(normalize=True)*100
print(card_type_dis)


zero_balance_customer = df.query("balance==0")
zero_balance_customer.head()


df.isna().sum()


df.duplicated().any()


data = df.drop(["rownumber","customerid","surname"],axis=1)
data.head()


exit_age = data[data['exited'] == 1]
sns.histplot(data['age'],bins=30, kde=True)
sns.histplot(exit_age['age'])
plt.show()


num_by_gender = data['gender'].value_counts(normalize=True, ascending=True)
print(f"{num_by_gender*100}")


plt.style.use('seaborn-v0_8')
data.groupby('gender')['balance'].sum()\
.plot(kind='bar')
plt.xlabel('gender')
plt.ylabel('balance')
plt.show()


sns.boxplot(x='gender', y='creditscore', data=data)
plt.show()


filtered_female_exited = data.query("gender=='Female' and  exited==1")
filtered_male_exited = data.query("gender == 'Male' and exited==1")
"The number of women who left the bank are {} and men are {}".format(filtered_female_exited.shape[0],filtered_male_exited.shape[0])


data['card_type'] = data['card_type'].astype('category').cat.codes


columns = ['exited','creditscore','numofproducts','estimatedsalary' 
           ,'tenure', 'age', 'balance','complain','isactivemember',
           'satisfaction_score','point_earned','card_type','hascrcard']
correlation = data[columns].corr(method='pearson')

sns.heatmap(correlation, cmap="BuPu")
plt.title('Correlation_Matrix')
plt.show()


from scipy.stats import pearsonr
r,p_value = pearsonr(data.complain, data.exited)
print(f"correlation coefficient:{r}, p_value:{p_value}")



sns.boxplot(x='geography', y='balance', data=data)
plt.show()


pivoted_data = pd.crosstab(data['geography'], data['exited'])
pivoted_data


#chi_square to tes if the Geography locations affects attition  rates 
#H0 = Exited is independent of geography
#H1 = exited is dependent of geography

import scipy.stats as stats

result = stats.chi2_contingency(pivoted_data)
print(result)


#pvalue is 5.24 which less than 0.05 we reject the null hypothesis
#hence there is significant between geography and exited



complaint_by_geography = data[data['complain']==1]
complaint_by_geography.groupby('geography')['complain'].value_counts()\
.plot(kind='bar', color=['b','y', 'k'])
plt.show()


#chi_square for whether there is a relationship between complaints and Geography
#H0: Geography and Complain re independent
#H1 :Geography and Complain are dependent
#alpha = 0.05
complaint_table = pd.crosstab(data['geography'],data['complain'])
contingency_results = stats.chi2_contingency(complaint_table)
print(contingency_results)
#p_value < 0.05,there is  significant relation between Geography and complaints so we reject the null hypothesis.


from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report,accuracy_score,roc_curve,auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import mlflow
import mlflow.sklearn


le = LabelEncoder()
data['gender'] = le.fit_transform(data['gender'])
data['geography'] = le.fit_transform(data['geography'])
data.head()


# Create an experiment name (like a folder for all your bank project runs)
experiment_name = "XYZ_Bank_Churn_Experiment"
if not mlflow.get_experiment_by_name(experiment_name):
    mlflow.create_experiment(experiment_name)

mlflow.set_experiment(experiment_name)


with mlflow.start_run(run_name="Baseline_With_Complain"):
    
    # 1. Data Prep
    X = data.drop('exited', axis=1)
    y = data['exited']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # 2. Model Training
    params = {"max_depth": 10, "n_estimators": 100, "max_features": 'log2'}
    rf = RandomForestClassifier(**params)
    rf.fit(X_train, y_train)
    
    # 3. Evaluation
    y_pred = rf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    Report = classification_report(y_test, y_pred)
    
    # 4. Logging
    mlflow.log_params(params)
    mlflow.log_param("includes_complain", True)
    mlflow.log_metric("accuracy", acc) # This is a number, so it works!
    
    # FIX: Log the Report as Text (Artifact) instead of a Metric
    mlflow.log_text(Report, "classification_report.txt")
    
    # Save the model
    mlflow.sklearn.log_model(rf, name="model_with_leakage")
    
    print(f"Run Finished! Accuracy with complain: {acc}")


y_prob = rf.predict_proba(X_test)[:,1]
fpr,tpr,thresholds = roc_curve(y_test,y_prob)
roc_auc = auc(fpr,tpr)
print(f'AUC score: {roc_auc}')

plt.plot(fpr, tpr)

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.show()


#Hyperparameter tuning and checking for data leakage :) since complain is used in 80% of the random forest

from sklearn.model_selection import cross_val_score

with mlflow.start_run(run_name="Cross_Validation_Leakage_Check"):
    
    # 1. Setup Data
    x_without_complain = data.drop(['complain', 'exited'], axis = 1)
    y = data['exited']
    params = {"max_depth": 10, "n_estimators": 100, "max_features": 'log2'}
    model = RandomForestClassifier(**params)
    
    # 2. Run Cross Validation
    # We log the results for the CLEAN model (without complain)
    scores_no_comp = cross_val_score(model, x_without_complain, y, cv=5)
    
    mean_acc = scores_no_comp.mean()
    std_dev = scores_no_comp.std()

    # 3. Log Everything to MLflow
    mlflow.log_params(params)
    mlflow.log_param("experiment_type", "Leakage_Validation")
    
    # We log the mean and the std_dev as separate metrics
    mlflow.log_metric("cv_mean_accuracy", mean_acc)
    mlflow.log_metric("cv_std_deviation", std_dev)
    
    print(f"Logged to MLflow -> Mean: {mean_acc:.4f}, Std: {std_dev:.4f}")
#the standard deviation is low which shows the model doesn't fluctuate a lot and is stable thus not overfitting
#the mean being 99.86% shows that our model is performing well
#As you can see the mean score increases upto 1 without complain and that improves the model's generalization across the board.
#Reasoning for doing this because of the feature_importance below which shows complain is adding noise and data leakage.


feature_importances = pd.Series(model.fit(X_train,y_train).feature_importances_, index=X_train.columns).sort_values(ascending=False)

feature_importances.plot.bar()
#The most important feature is complain,Age then NumofProducts



